# MapReduce

## I · 概述

​	  MapReduce是一个编程模型，也是一个处理和生成超大数据集的算法模型的相关事项。用户定义一个`map`函数处理一个k/v数据集合的输入，然后产生一个k/v数据集的输出，再定义一个`reduce`函数，对于相同key的数据进行合并。

​	MapReduce架构的程序能够在大量的普通配置的计算机上实现并行化处理，这个系统运行时只关心：如何分割输入数据，在大量计算机组成的集群上调度，集群中计算机的错误处理，管理集群中计算机之间必要的通信。

## II · 编程模型

​	MapReduce编程模型的原理：利用一个输入k/v集合产生一个输出k/v集合。用户自定Map函数接收一个k/v值的输入，然后产生一个k/v值的输出，再通过Reduce函数将具有相同中间key值的value集合进行合并。

#### 例子 - 计算一个大的文档集合中每个单词出现的次数

```python
map(String key, String value):
    // key: document name
    // value: document contents
	for each word w in value:
        EimtIntermediate(w, "1");
    

reduce(String key, Iterator values):
    // key: a word
    // values: a list of counts
    int result = 0;
    for each v in values:
        result += ParseInt(v);
    Emit(AsString(result));
```

- 分布式grep

  Map函数输出匹配某个模式的一行，Reduce函数是一个恒等函数，把中间数据复制到输出。

- 计算URL访问频率

  Map函数处理日志中web页面请求的记录，然后输出(URL, 1)。Reduce函数把相同URL的value值都累加起来，产生(URL, 记录总数)结果。

- 倒转网络链接图

  Map函数在源页面(source)中搜索所有的链接目标(target)并输出为(target, source)。Reduce函数把给定链接目标(target)的链接组合成一个列表，输出(target, list(source))。

- 每个主机的检索词向量

  检索词向量用一个(词，频率)列表来概述出现在文档或文档集中的最重要的一些词。Map函数为每一个输入文档输出(主机名，检索词向量)，其中主机名来自文档的URL。Reduce函数接收给定主机的所有文档的检索词向量，并把这些检索词向量加在一起，丢到低频的检索词，输出一个最终的(主机名，检索词向量)。

- 倒排索引

  Map函数分析每个文档输出一个(词，文档号)的列表，Reduce函数的输入是一个给定词的所有(词，文档号)，排序所有的文档号，输出(词，list(文档号))。所有的输出集合形成一个简单的倒排索引，它以一种简单的算法跟踪词在文档中的位置。

- 分布式排序

  Map函数从每个记录提取key，输出(key, record)。Reduce函数不改变任何值。

## III · 实现

​	MapReduce模型可以有多种不同实现方式，如何选择取决于生产环境，有的适用于小型机共享内存，有的适用于大型NUMA架构的多处理器主机，有的则适合大型的网络连接集群。而我们所讨论的则是用以太网交换机、普通PC构成的大型集群。

### 1. 执行流程

​	将Map函数的输入数据自动分割为M个数据片段集合，并分布到多台机器上执行。输入的数据片段能够在不同机器上并行处理。使用分区函数将Map产生的中间key值分成R个不同分区(如，hash(key) mod R)，Reduce也被分布到多台机器上执行。分区数量和分区函数由用户来指定。

1. 用户程序首先调用MapReduce库将输入文件分成M个数据片段，每个数据片段的大小一般从16MB到64MB(通过可选参数可以控制)。然后用户程序在集群中创建大量的程序副本。

2. 这些程序副本中有个特殊的master程序，其他则都是worker，由master进行任务的分配。有M个Map任务和R个Reduce任务，master则将一个Map任务或Reduce任务分配给一个空闲的worker。

3. 被分配了Map任务的worker进程读取相关的输入数据片段，从输入数据中解析出k/v对，然后把k/v对传递给用户自定义的Map函数，由Map函数生成中间k/v数据对，并缓存在内存中。

4. 缓存中的k/v数据对通过分区函数分成R个区域，之后周期性的写入到本地磁盘上。缓存的k/v数据对在本地磁盘上存储的位置会传递给master，由master负责把这些位置传递给Reduce任务的worker。

5. 当Reduce任务的worker进程接收到master发送来的数据存储位置后，使用RPC从Map任务的worker所在主机的磁盘上读取这些数据。当Reduce worker读取了所有的中间数据后，通过key进行排序后使得具有相同key值的数据聚合在一起。由于许多不同的key值会映射到相同的Reduce任务上，因此必须进行排序。如果中间数据太大无法在内存中完成排序，那么要在外部进行排序。

6. Reduce worker进程遍历排序后的中间数据，对于每一个唯一的中间key值，Reduce worker将这个key值和它相关的中间value集合传给用户自定义的Reduce函数。Reduce函数的输出被追加到所属分区的输出文件中。

7. 当所有的Map和Reduce任务都完成之后，master唤醒用户程序。这时，用户程序里对MapReduce的调用才返回。

​	在成功完成任务之后，MapReduce的输出存放在R个输出文件中(每个Reduce任务对应一个输出文件)。一般情况下，用户不需要将这R个输出文件合并成一个文件——而是经常将这些文件作为另一个MapReduce的输入，或者在另一个可以处理多个分割文件的分布式应用中使用。

### 2. Master数据结构

​	Master持有一些数据结构，它存储每一个Map和Reduce任务的状态(空闲、工作中或完成)，以及Worker机器(非空闲任务的机器)的标识。

​	Master就像一个数据管道，中间文件存储的位置信息通过这个管道从Map传递到Reduce。因此，对于每个以及完成的Map任务，master存储了Map任务产生的R个中间文件存储区域的大小和位置。当Map任务完成时，Master接收到位置和大小的更新信息，这些信息被逐步递增的推送给那些正在工作的Reduce任务。

### 3. 容错

​	MapReduce的设计初衷是由大量机器组成的集群来处理超大规模的数据，所以应该具备良好的容错机制。

#### 3.1 worker故障

​	master周期性的ping每个worker，如果在一个约定的时间内没有收到worker返回的信息，master将该worker标记为失效，所有由这个失效的worker完成的Map任务被重设为初始的空闲状态，之后这些任务就可以被安排给其他worker。同样的，worker失效时正在运行的Map或Reduce任务也将被重新置为空闲状态，等待重新调度。

​	当worker故障时，由于已经完成的Map任务的输出存储在这台机器上，Map的输出已经不可访问了，因此必须重新执行，而已经完成的Reduce任务的输出存储在全局文件系统上，因此不需要重新执行。

​	当一个Map任务首先被worker A执行，之后由于worker A失效了又被调度到worker B执行，这个“重新执行”的动作会被通知给所有执行Reduce任务的worker，任何还没有从worker A读取数据的Reduce任务将从worker    B读取数据。

#### 3.2 master故障

​	一个简单的解决办法是让master周期性的将其保存的数据状态写入磁盘，即检查点(checkpoint)。如果这个master任务失效了，可以从最后一个检查点开始启动另一个master进程。但是由于只有一个master进程，失效后再恢复是非常麻烦的，如果master失效就终止MapReduce运算。

#### 3.3 故障处理机制

​	我们依赖Map和Reduce任务的原子性保证在没有错误情况下输出与顺序执行相同。每个工作中的任务把它的输出写到私有的临时文件中，每个Reduce任务生成一个文件，每个Map任务生成R个文件。当一个Map任务完成时，worker发送一个包含R个临时文件名的完成消息给master。如果master从一个已经完成的Map任务再次接受到一个完成消息，master将忽略这个消息；否则，master将这R个文件的名字记录在数据结构里。

​	当Reduce任务完成时，Reduce worker进程以原子的方式把临时文件重命名为最终的输出文件。如果同一个Reduce任务在多台机器上执行，针对同一个最终输出文件将有多个重命名操作执行。我们依赖底层文件系统提供的重命名操作的原子性来保证最终文件系统状态仅包含一个Reduce任务产生的数据。

#### 3.4 存储位置

​	在计算运行环境中，网络带宽是一个匮乏的资源，通过尽量把输入数据(由GFS管理)存储在集群中机器的本地磁盘上来节省带宽。GFS把每个文件按64MB一个Block分隔，每个Block保存在多台机器上，环境中就存放了多份拷贝(一般是3份)。MapReduce的master在调度Map任务时会考虑输入文件的位置信息，尽量将一个Map任务调度包含相关输入数据拷贝的机器上执行，如果没能做到，那么master将尝试在保存有输入数据拷贝的机器的附近的机器上执行Map任务(例如，分配到一个和包含输入数据的机器在一个switch里的worker机器上执行)。当一个足够大的cluster集群上运行大型MapReduce操作的时候，大部分的输入数据都能从本地机器读取，因此消耗非常少的网络带宽。

### 4. 技巧

#### 4.1 分区函数

​	MapReduce的使用者通常会指定Reduce任务和Reduce任务输出文件的数量(R)。我们在中间key上使用分区函数来对数据进行分区，一个缺省的分区函数是hash方法(hash(key) mod R)进行分区。有时候其他一些分区函数也是很有用的，比如输出key值是URLs，将每个主机的所有条目保持在同一个输出文件中。

#### 4.2 顺序保证

​	我们确保在给定的分区中，中间kv数据的处理顺序是按照key值增量顺序处理的。这样的顺序保证对每个分区生成一个有序的输出文件，这对于需要对输出文件按照key值随机存取的应用非常有意义，对在排序输出的数据集也很有帮助。

#### 4.3 Combiner函数

​	有些情况下，Map函数产生的中间key值的重复数据会占很大的比例，这时通过指定一个可选的combiner函数对这些重复数据进行一次合并，然后通过网络发送可以很好的节省带宽。

​	Combiner函数在每台执行Map任务的机器上都会被执行一次，一般情况下Combiner和Reduce函数是一样的，它们唯一的区别就是MapReduce怎样控制函数的输出。Reduce的输出被保存在最终文件里，而Combiner函数的输出则被写到中间文件再传给Reduce。



# 6.824 Lab1

